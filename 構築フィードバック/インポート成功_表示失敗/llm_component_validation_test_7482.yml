app:
  description: "LLMコンポーネントのコーディングルールを検証するためのテストアプリケーション。異なるtemperature設定での応答を比較し、変数参照やプロンプトテンプレートの動作を確認します。"
  icon: "🧪"
  icon_background: "#FF6B6B"
  mode: advanced-chat
  name: "LLMコンポーネント検証テスト"
  use_icon_as_answer_icon: false

dependencies: []

kind: app
version: 0.3.0

workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      enabled: false
    opening_statement: |
      LLMコンポーネント検証テストへようこそ！
      
      このアプリケーションは、異なる温度設定（0.1、0.5、0.9）での応答を比較し、LLMコンポーネントの動作を検証します。
      
      テストしたい内容を入力してください：
      - 短い質問や文章
      - 要約してもらいたいテキスト
      - 創造的な解釈を求める内容
    retriever_resource:
      enabled: false
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions:
      - "人工知能の未来について教えてください"
      - "量子コンピュータの基本原理を説明してください"
      - "地球温暖化対策として個人ができることは何ですか"
      - "宇宙の起源について現在の科学的理解を教えてください"
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
  graph:
    edges:
      - data:
          isInLoop: false
          sourceType: start
          targetType: llm
        id: start-factual-edge
        selected: false
        source: start_node
        sourceHandle: source
        target: factual_llm_node
        targetHandle: target
        type: custom
        zIndex: 0
      - data:
          isInLoop: false
          sourceType: start
          targetType: llm
        id: start-balanced-edge
        selected: false
        source: start_node
        sourceHandle: source
        target: balanced_llm_node
        targetHandle: target
        type: custom
        zIndex: 0
      - data:
          isInLoop: false
          sourceType: start
          targetType: llm
        id: start-creative-edge
        selected: false
        source: start_node
        sourceHandle: source
        target: creative_llm_node
        targetHandle: target
        type: custom
        zIndex: 0
      - data:
          isInLoop: false
          sourceType: llm
          targetType: llm
        id: factual-integration-edge
        selected: false
        source: factual_llm_node
        sourceHandle: source
        target: integration_llm_node
        targetHandle: target
        type: custom
        zIndex: 0
      - data:
          isInLoop: false
          sourceType: llm
          targetType: llm
        id: balanced-integration-edge
        selected: false
        source: balanced_llm_node
        sourceHandle: source
        target: integration_llm_node
        targetHandle: target
        type: custom
        zIndex: 0
      - data:
          isInLoop: false
          sourceType: llm
          targetType: llm
        id: creative-integration-edge
        selected: false
        source: creative_llm_node
        sourceHandle: source
        target: integration_llm_node
        targetHandle: target
        type: custom
        zIndex: 0
      - data:
          isInLoop: false
          sourceType: llm
          targetType: answer
        id: integration-answer-edge
        selected: false
        source: integration_llm_node
        sourceHandle: source
        target: answer_node
        targetHandle: target
        type: custom
        zIndex: 0
    nodes:
      - data:
          desc: "ユーザー入力を受け取る開始ノード"
          selected: false
          title: "開始"
          type: start
          variables:
            - label: "テスト入力"
              max_length: 5000
              options: []
              required: true
              type: paragraph
              variable: user_input
        height: 116
        id: start_node
        position:
          x: 50
          y: 250
        positionAbsolute:
          x: 50
          y: 250
        selected: false
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
      - data:
          context:
            enabled: false
            variable_selector: []
          desc: "低温度設定（0.1）で事実ベースの要約生成を検証"
          memory:
            enabled: false
          model:
            completion_params:
              max_tokens: 1000
              temperature: 0.1
              top_p: 0.5
            mode: chat
            name: gpt-4
            provider: openai
          prompt_template:
            - id: system-prompt-factual
              role: system
              text: |
                あなたは正確性を重視する情報アナリストです。
                以下のルールに厳密に従って回答してください：
                1. 事実のみを述べる
                2. 推測や個人的な意見は含めない
                3. 客観的で中立的な表現を使用
                4. 情報源が不明確な場合は明記する
            - id: user-prompt-factual
              role: user
              text: |
                以下の内容について、事実ベースの要約を提供してください：
                
                {{#start_node.user_input#}}
          selected: false
          structured_output_enabled: false
          title: "事実ベースLLM（温度0.1）"
          type: llm
          variables: []
          vision:
            enabled: false
        height: 98
        id: factual_llm_node
        position:
          x: 350
          y: 100
        positionAbsolute:
          x: 350
          y: 100
        selected: false
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
      - data:
          context:
            enabled: false
            variable_selector: []
          desc: "中温度設定（0.5）でバランスの取れた分析を検証"
          memory:
            enabled: false
          model:
            completion_params:
              max_tokens: 1000
              temperature: 0.5
              top_p: 0.7
            mode: chat
            name: gpt-4
            provider: openai
          prompt_template:
            - id: system-prompt-balanced
              role: system
              text: |
                あなたはバランスの取れた分析を行うコンサルタントです。
                以下のガイドラインに従って回答してください：
                1. 事実と解釈の両方を含める
                2. 複数の視点を考慮する
                3. 実用的な洞察を提供
                4. 明確で構造化された回答
            - id: user-prompt-balanced
              role: user
              text: |
                以下の内容について、バランスの取れた分析を提供してください：
                
                {{#start_node.user_input#}}
          selected: false
          structured_output_enabled: false
          title: "バランス型LLM（温度0.5）"
          type: llm
          variables: []
          vision:
            enabled: false
        height: 98
        id: balanced_llm_node
        position:
          x: 350
          y: 250
        positionAbsolute:
          x: 350
          y: 250
        selected: false
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
      - data:
          context:
            enabled: false
            variable_selector: []
          desc: "高温度設定（0.9）で創造的な解釈を検証"
          memory:
            enabled: false
          model:
            completion_params:
              max_tokens: 1000
              temperature: 0.9
              top_p: 0.95
            mode: chat
            name: gpt-4
            provider: openai
          prompt_template:
            - id: system-prompt-creative
              role: system
              text: |
                あなたは創造的な思考を得意とするイノベーターです。
                以下の方針で回答してください：
                1. 独創的なアイデアを探求
                2. 既成概念にとらわれない発想
                3. 新しい可能性を提案
                4. インスピレーションを与える表現
            - id: user-prompt-creative
              role: user
              text: |
                以下の内容について、創造的な解釈や新しい視点を提供してください：
                
                {{#start_node.user_input#}}
          selected: false
          structured_output_enabled: false
          title: "創造的LLM（温度0.9）"
          type: llm
          variables: []
          vision:
            enabled: false
        height: 98
        id: creative_llm_node
        position:
          x: 350
          y: 400
        positionAbsolute:
          x: 350
          y: 400
        selected: false
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
      - data:
          context:
            enabled: true
            variable_selector:
              - start_node
              - user_input
          desc: "3つの異なる応答を統合して比較分析を行う"
          memory:
            enabled: true
            role_prefix:
              assistant: "分析結果："
              user: "入力："
            window:
              enabled: true
              size: 5
          model:
            completion_params:
              max_tokens: 2000
              temperature: 0.3
            mode: chat
            name: gpt-4
            provider: openai
          prompt_template:
            - id: system-prompt-integration
              role: system
              text: |
                あなたは比較分析の専門家です。
                3つの異なるアプローチによる応答を統合し、以下の形式で包括的な分析を提供してください：
                
                1. 各アプローチの特徴と強み
                2. 共通点と相違点の分析
                3. 状況に応じた使い分けの提案
                4. 総合的な結論と推奨事項
                
                出力は明確な構造とマークダウン形式を使用してください。
            - id: user-prompt-integration
              role: user
              text: |
                元の入力：
                {{#start_node.user_input#}}
                
                ## 事実ベースの応答（温度0.1）
                {{#factual_llm_node.text#}}
                
                ## バランス型の応答（温度0.5）
                {{#balanced_llm_node.text#}}
                
                ## 創造的な応答（温度0.9）
                {{#creative_llm_node.text#}}
                
                上記の3つの応答を比較分析し、それぞれの特徴と適用場面について説明してください。
          selected: false
          structured_output_enabled: false
          title: "統合分析LLM"
          type: llm
          variables: []
          vision:
            enabled: false
        height: 98
        id: integration_llm_node
        position:
          x: 650
          y: 250
        positionAbsolute:
          x: 650
          y: 250
        selected: false
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
      - data:
          answer: |
            # LLMコンポーネント検証結果
            
            {{#integration_llm_node.text#}}
            
            ---
            
            ## 検証項目の確認結果
            ✅ LLMノードの必須パラメータ設定：完了
            ✅ prompt_template配列形式：正常動作
            ✅ 変数参照形式（{{#node_id.variable#}}）：正常動作
            ✅ completion_params設定：各温度設定で期待通りの動作
            ✅ memory/context設定：統合ノードで正常動作確認
            
            ### 使用されたモデル設定
            - 事実ベース：temperature=0.1, top_p=0.5
            - バランス型：temperature=0.5, top_p=0.7
            - 創造的：temperature=0.9, top_p=0.95
          desc: "検証結果と統合分析を表示"
          selected: false
          title: "回答"
          type: answer
          variables: []
        height: 374
        id: answer_node
        position:
          x: 950
          y: 250
        positionAbsolute:
          x: 950
          y: 250
        selected: false
        sourcePosition: right
        targetPosition: left
        type: custom
        width: 244
    viewport:
      x: 0
      y: 0
      zoom: 0.8