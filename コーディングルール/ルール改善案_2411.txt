# Dify YMLコーディングルール改善案

## 改善が必要な箇所と改善内容

### 1. 全体コーディングルール（全体コーディングルール.md）への追加

#### セクション7.1 バージョン管理の後に追加
##### 7.3 モデル選択とトークン制限
```
### 7.3 モデル選択とトークン制限ガイドライン

#### 7.3.1 主要モデルのトークン制限
| モデル | 最大コンテキスト長 | 推奨max_tokens | 用途 |
|--------|------------------|----------------|------|
| gpt-4 | 8,192 | 1,000-2,000 | 詳細な分析・要約 |
| gpt-4-turbo | 128,000 | 2,000-4,000 | 大量データ処理 |
| gpt-3.5-turbo | 16,384 | 1,000-2,000 | 高速処理 |
| claude-3-opus | 200,000 | 2,000-4,000 | 超大量データ処理 |

#### 7.3.2 トークン使用量の計算
- 入力トークン = システムプロンプト + ユーザープロンプト + 変数展開後のテキスト
- 出力トークン = max_tokens設定値
- 総トークン = 入力トークン + 出力トークン
- **重要**: 総トークン < モデルの最大コンテキスト長

#### 7.3.3 WEB検索結果を扱う際の注意
- WEB検索結果は予測不可能なサイズになる可能性がある
- 必ず以下の対策のいずれかを実装すること：
  1. トークン制限に余裕のあるモデルを使用（gpt-4-turbo、claude-3等）
  2. 検索結果を前処理するcodeノードを挿入
  3. max_resultsを制限（3-5個推奨）
  4. include_raw_contentを無効化
```

### 2. WEB検索コンポーネントルール（コンポーネント記述ルール_WEB検索.txt）への追加

#### オプションパラメータセクションの後に追加
```
■検索結果サイズの管理

### トークン制限対策
WEB検索結果は大量のテキストを含む可能性があるため、以下の対策を推奨：

1. **基本設定（トークン制限対策）**
   ```yaml
   tool_configurations:
     max_results: 3          # 5以下を推奨
     include_raw_content: 0  # 0を推奨（生のHTMLを含めない）
     include_answer: 1       # 1を推奨（要約版を取得）
   ```

2. **後続LLMノードの設定**
   - gpt-4使用時：入力データサイズに注意
   - 大量データ処理時：gpt-4-turbo以上を推奨
   - エラー回避のため、buffer設定を考慮

3. **前処理パターン（推奨）**
   ```yaml
   # WEB検索 → 前処理（code） → LLM の構成
   - WEB検索ノードで結果取得
   - codeノードで結果を要約・切り詰め
   - LLMノードで最終処理
   ```

### エラーハンドリング例
```python
# codeノードでの前処理例
def preprocess_search_results(search_text):
    # トークン数の概算（1文字≒0.5トークン）
    estimated_tokens = len(search_text) * 0.5
    
    if estimated_tokens > 3000:
        # 結果を切り詰め
        return search_text[:6000]  # 約3000トークン
    return search_text
```
```

### 3. 品質チェックリスト（品質チェックリスト.md）への追加

#### セクション4.2 llmノードの後に追加
```
### 4.2.1 LLMノードのトークン制限チェック
- [ ] 使用するモデルの最大コンテキスト長を把握している
- [ ] 入力データサイズを考慮したモデル選択をしている
- [ ] WEB検索結果を扱う場合、トークン制限対策を実装している
- [ ] max_tokensが（最大コンテキスト長 - 想定入力トークン数）以下である
- [ ] 大量データ処理時は、以下のいずれかを実装：
  - [ ] gpt-4-turbo以上のモデルを使用
  - [ ] 前処理ノードでデータサイズを制御
  - [ ] 検索結果の数を制限（max_results: 3-5）
```

### 4. クラッシュ事項チェックリスト（クラッシュ事項チェックリスト.md）への追加

#### セクション5 LLMノード関連に追加
```
### 5.3 トークン制限エラー防止
- [ ] gpt-4使用時、総トークン数が8192以下であることを確認
- [ ] WEB検索結果をLLMに渡す場合、以下のいずれかを実装：
  - [ ] max_resultsを5以下に設定
  - [ ] include_raw_contentを0に設定
  - [ ] 前処理ノードでサイズ制御
  - [ ] より大きなコンテキストのモデルを使用
- [ ] プロンプトテンプレートが過度に長くない
- [ ] 変数展開後の総文字数を概算している
```

## 実装優先度
1. **最優先**: クラッシュ事項チェックリストへの追加（即座のエラー防止）
2. **高**: WEB検索コンポーネントルールへの追加（頻出パターンの対策）
3. **中**: 全体コーディングルールへの追加（設計指針の明確化）
4. **低**: 品質チェックリストへの追加（品質向上）

## 追加推奨事項
1. エラー事例集の作成と共有
2. モデル選択フローチャートの作成
3. トークン計算ツールの導入検討